# ChatGroq with LLaMA3 Demo

This project is a Streamlit-based web application that allows users to interact with documents using LLaMA3 via ChatGroq. The app ingests PDF documents, creates vector embeddings using FAISS, and retrieves document-based answers through a conversational interface.

# ğŸ”§ Features
Upload and embed a directory of PDFs using PyPDFDirectoryLoader

Vectorize documents with FAISS and OllamaEmbeddings

Query documents using natural language

Retrieve accurate context-based answers using LLaMA3 (Groq API)

View similar documents retrieved from vector search

# ğŸ› ï¸ Tech Stack
Streamlit â€“ UI Framework

LangChain â€“ Document loading, chaining, and vector search

FAISS â€“ Vector similarity search

Groq â€“ LLM API backend (LLaMA3)

OllamaEmbeddings â€“ Text embedding model

dotenv â€“ Environment variable management

# âœ¨ How It Works
Document Embedding:

Click the "Documents Embedding" button to load, chunk, and vectorize the PDF files.

Ask a Question:

Enter a question related to the embedded documents in the input box.

Receive Answer:

The LLM processes your question using the most relevant documents and responds accurately.

Document Context:

Expand the â€œDocument Similarity Searchâ€ section to see which document snippets were retrieved to answer the question.
